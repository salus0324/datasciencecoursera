mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
ts1<-ts(googOpen, frequency=12)
ts1<-ts(googOpen, frequency=12)
mGoog
plot(ts1, xlab="Years+1", ylab="GOOG")
plot(ts1, xlab="Years+1", ylab="GOOG")
plot(decompose(ts1), xlab="years+1")
#Training and test sets
ts1Train <- window(ts1, start=1, end=5)
tsTest <- window(ts1, start=5, end=(7-0.01))
tsTrain
#Training and test sets
ts1Train <- window(ts1, start=1, end=5)
ts1Test <- window(ts1, start=5, end=(7-0.01))
ts1Train
#Simple moving average
plot(ts1Train)
lines(ma(ts1Train, order=3), col="red")
#Simple moving average
plot(ts1Train)
lines(ma(ts1Train, order=3), col="red")
install.packages("forecast")
lines(ma(ts1Train, order=3), col="red")
#Simple moving average
library(forecast)
plot(ts1Train)
lines(ma(ts1Train, order=3), col="red")
#Exponential smoothing
ets1 <- ets(ts1Train, model="MMM")
fcast <- forecast(ets1)
plot(fcast)
lines(ts1Test, col="red")
accuracy(fcast, ts1Test)
#######
#Unsupervised prediction
#Iris example ignoring species labels
data(iris)
library(ggplot2)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
kMeans1 <- kmeans(subset(training, select=-c(Species)), centers=3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width, Petal.Length, colour=clusters, data=training)
table(kMeans1$cluster, training$Species)
modFit <- train(clusters~., data=subset(training, select=-c(Species)), method="rpart")
table(predict(modFit, training), training$Species)
#Apply on test
testClusterPred <- predict(modFit, testing)
table(testClusterPred, testing$Species)
#Problem 1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(38833)
modRF <- train(y~., method ='rf', data=vowel.train)
modBOOST<- train(y~., method ='gbm', data=vowel.train)
predRF <- predict(modRF, vowel.test)
predBOOST <- predict(modBOOST, vowel.test)
accuracy(predRF, vowel.test$y)
confusionMatrix(predRF, vowel.test$y)
confusionMAtrix(predBOOSt, vowel.test$y)
confusionMatrix(predBOOSt, vowel.test$y)
confusionMatrix(predBOOST, vowel.test$y)
head(preRF)
head(predRF)
RF_accuracy = sum(predRF==vowel.test$y)/length(predRF)
RF_accuracy
confusionMatrix(predRF, vowel.test$y)
RF_accuracy = sum(predBOOST==vowel.test$y)/length(predBOOST)
confusionMatrix(predRF, vowel.test$y)$accuracy
confusionMatrix(predRF, vowel.test$y)$Accuracy
confusionMatrix(predRF, vowel.test$y)$Sensitivity
RF_accuracy <- sum(predRF==vowel.test$y)/length(predRF)
RF_accuracy <- sum(predBOOST==vowel.test$y)/length(predBOOST)
agreed_index <- vowel.test[predRF==predBOOST,]
agreed_Testindex <- vowel.test[predRF==predBOOST,]
agreedpredict <- predict(modRF, agreed_Testindex)
agreed_TestData <- vowel.test[predRF==predBOOST,]
agreedpredict <- predict(modRF, agreed_TestData)
agreed_TestData <- vowel.test[predRF==predBOOST,]
agreement_accuracy <- sum(agreedpredict==agreed_TestData$y)/length(agreedpredict)
agreedpredict <- predict(modRF, agreed_TestData)
BOOST_accuracy <- sum(predBOOST==vowel.test$y)/length(predBOOST)
c(RF_accuracy, BOOST_accuracy, agreement_accuracy)
RF_accuracy <- sum(predRF==vowel.test$y)/length(predRF)
BOOST_accuracy <- sum(predBOOST==vowel.test$y)/length(predBOOST)
agreed_TestData <- vowel.test[predRF==predBOOST,]
agreedpredict <- predict(modRF, agreed_TestData)
agreement_accuracy <- sum(agreedpredict==agreed_TestData$y)/length(agreedpredict)
c(RF_accuracy, BOOST_accuracy, agreement_accuracy)
#Problem2
#######
#Problem2
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
training = adData[ inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
testing = adData[-inTrain,]
set.seed(32433)
set.seed(62433)
mod1<- train(diagnosis~., method ='rf', data=training)
mod2 <- train(diagnosis~., method ="gbm", data=training)
mod3 <- train(diagnosis~., method ="lda", data=training)
pred1 <- predict(mod1, testing)
pred2 <- predict(mod2, testing)
pred3 <- predict(mod3, testing)
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combModFit <- train(diagnosis~., method="gam", data=predDF)
combPred <- predict(combModFit, predDF)
sqrt(sum((pred1-testing$wage)^2))
sqrt(sum((pred1-testing$diagnosis)^2))
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combModFit <- train(diagnosis~., method="gam", data=predDF)
combPred <- predict(combModFit, predDF)
head(combPred)
unique(testing$diagnosis)
mod1_accuracy <- sum(pred1==testing$diagnosis)/length(pred1)
mod2_accuracy <- sum(pred2==testing$diagnosis)/length(pred2)
mod3_accuracy <- sum(pred3==testing$diagnosis)/length(pred3)
comb_accuracy <- sum(combPred==testing$diagnosis)/length(combPred)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
set.seed(62433)
#Build three different models
mod1<- train(diagnosis~., method ='rf', data=training)
mod2 <- train(diagnosis~., method ="gbm", data=training)
mod3 <- train(diagnosis~., method ="lda", data=training)
combModFit <- train(diagnosis~., method="rf", data=predDF)
combPred <- predict(combModFit, predDF)
mod1_accuracy <- sum(pred1==testing$diagnosis)/length(pred1)
mod2_accuracy <- sum(pred2==testing$diagnosis)/length(pred2)
mod3_accuracy <- sum(pred3==testing$diagnosis)/length(pred3)
comb_accuracy <- sum(combPred==testing$diagnosis)/length(combPred)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
#Problem3
####
#Problem3
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
names(training)
modlasso <- train(CompressiveStrength,method="lasso", data=training)
modlasso <- train(CompressiveStrength~.,method="lasso", data=training)
modlasso <- train(CompressiveStrength~.,method="lasso", data=training)
?plot.enet
plot.enet(modlasso)
install.packages(elasticnet)
install.packages("elasticnet")
install.packages("elasticnet")
library(elasticent)
library(elasticnet)
plot.enet(modlasso)
plot.enet(modlasso$enet)
data(diabetes)
names(diabetes)
predictLasso <- predict(modlasso, testing)
onject <- enet(predictLasso)
onject <- enet(testing,predictLasso)
onject <- enet(testing$CompressiveStrength,predictLasso)
plot.enet(modlasso$finalModel)
?plot.ent
?plot.enet
plot.enet(modlasso$finalModel)
?plot.enet
plot.enet(modlasso$finalModel, xvar="step")
?plot.enet
data(diabetes)
attach(diabetes)
par(mfrow=c(2,2))
object <- enet(x,y,lambda=1)
plot(object)
plot(object,xvar="step")
plot.enet(modlasso$finalModel, xvar="step")
plot.enet(modlasso$finalModel, xvar="step")
plot.enet(modlasso$finalModel, xvar="step")
#####
#Problem4
library(lubridate) # For year() function below
dat = read.csv("~/gaData.csv")
setwd("C:/Users/kshim/Documents/Coursera/datasciencecoursera/8. Machine Learning")
source('C:/Users/kshim/Documents/Coursera/datasciencecoursera/8. Machine Learning/wk4_quiz.R', echo=TRUE)
dat = read.csv("~/gaData.csv")
#####
#Problem4
library(lubridate) # For year() function below
dat = read.csv("~/gaData.csv")
setwd("C:/Users/kshim/Documents/Coursera/datasciencecoursera/8. Machine Learning")
dat = read.csv("~/gaData.csv")
dat = read.csv("~gaData.csv")
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forcast)
?bats
library(forcast)
library(forecast)
?bats
bats(tstrain)
plot.enet(modlasso$finalModel, xvar="lambda")
plot(modlasso$finalModel, xvar="lambda")
.enet
plot.enet(modlasso$finalModel, xvar="step")
mod <- bats(tstrain)
predict(mod, ts(testing$visitsTumblr), interval="predict")
predict(mod, ts(testing), interval="predict")
predict(mod, ts(testing), interval="predict")
predict(mod, ts(testing$visitsTumblr), interval="predict")
ttest <- ts(testing$visitsTumblr)
mod <- bats(tstrain)
pred <-forecast(mod, h=lengt(ttest), level=c(95))
pred <-forecast(mod, h=length(ttest), level=c(95))
?forecast
accuracy(pred, ttest)
pred <-forecast(mod, h=length(ttest), level=c(95))
accuracy(pred, ttest)
accuracy(pred, testing$visitsTumblr)
accuracy_percentage <- sum(pred==testing$visitsTumblr)/length(pred)
head(pred)
head(testing$visitsTumblr)
pred$level
pred$model
pred$upper
pred$residuals
accuracy(pred, testing$visitsTumblr)
?accuracy
pred
pred$model
plot(pred)
lines(ttest, col="red")
accuracy_percentage <- sum(testing$visitsTumblr<=pred$upper)/length(pred)
accuracy_percentage
mod <- bats(tstrain)
pred <-forecast(mod, h=length(ttest), level=c(95))
pred <-forecast(mod, h=length(ttest), level=0.95
pred <-forecast(mod, h=length(ttest), level=0.95)
pred <-forecast(mod, h=length(ttest), level=0.95)
accuracy(pred, testing$visitsTumblr)
accuracy_percentage <- sum(testing$visitsTumblr<=pred$upper)/length(pred)
accuracy_percentage
accuracy_percentage <- sum(testing$visitsTumblr<=pred$upper)/length(testing$visitsTumbl)
accuracy_percentage
?forecast
accuracy_percentage <- sum(pred$lower<=testing$visitsTumblr<=pred$upper)/length(testing$visitsTumbl)
accuracy_percentage <- sum(pred$lower=<testing$visitsTumblr<=pred$upper)/length(testing$visitsTumbl)
accuracy_percentage <- sum(pred$lower<= testing$visitsTumblr&testing$visitsTumblr<=pred$upper)/length(testing$visitsTumbl)
accuracy_percentage
###problem5
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
install.packages("e1071")
library(e1071)
modSVM <- svm(CompressiveStrength, data=training)
modSVM <- svm(CompressiveStrength, data=training)
modSVM <- svm(CompressiveStrength~., data=training)
predSVM <- predict(modSVM, testing)
predSVM
sqrt(mean(testing$CompressiveStrength-predSVM))
sqrt(mean(testing$CompressiveStrength-predSVM)^2)
rsmeSVM <- rmse(predSVM, testing$CompressiveStrength)
install.packages("hydroGOF")
library(hydroGOF)
rsmeSVM <- rmse(predSVM, testing$CompressiveStrength)
rsmeSVM
set.seed(38833)
modRF <- train(y~., method ='rf', data=vowel.train)
modBOOST<- train(y~., method ='gbm', data=vowel.train)
predRF <- predict(modRF, vowel.test)
predBOOST <- predict(modBOOST, vowel.test)
RF_accuracy <- sum(predRF==vowel.test$y)/length(predRF)
BOOST_accuracy <- sum(predBOOST==vowel.test$y)/length(predBOOST)
agreed_TestData <- vowel.test[predRF==predBOOST,]
agreedpredict <- predict(modRF, agreed_TestData)
agreement_accuracy <- sum(agreedpredict==agreed_TestData$y)/length(agreedpredict)
c(RF_accuracy, BOOST_accuracy, agreement_accuracy)
set.seed(62433)
#Build three different models
mod1<- train(diagnosis~., method ='rf', data=training)
mod2 <- train(diagnosis~., method ="gbm", data=training)
mod3 <- train(diagnosis~., method ="lda", data=training)
pred2 <- predict(mod2, testing)
pred1 <- predict(mod1, testing)
pred3 <- predict(mod3, testing)
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combPred <- predict(combModFit, predDF)
combModFit <- train(diagnosis~., method="rf", data=predDF)
mod1_accuracy <- sum(pred1==testing$diagnosis)/length(pred1)
mod2_accuracy <- sum(pred2==testing$diagnosis)/length(pred2)
mod3_accuracy <- sum(pred3==testing$diagnosis)/length(pred3)
comb_accuracy <- sum(combPred==testing$diagnosis)/length(combPred)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
#######
#Problem2
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
#Build three different models
mod1<- train(diagnosis~., method ='rf', data=training)
mod2 <- train(diagnosis~., method ="gbm", data=training)
mod3 <- train(diagnosis~., method ="lda", data=training)
pred1 <- predict(mod1, testing)
pred2 <- predict(mod2, testing)
pred3 <- predict(mod3, testing)
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combModFit <- train(diagnosis~., method="rf", data=predDF)
combPred <- predict(combModFit, predDF)
mod1_accuracy <- sum(pred1==testing$diagnosis)/length(pred1)
mod2_accuracy <- sum(pred2==testing$diagnosis)/length(pred2)
mod3_accuracy <- sum(pred3==testing$diagnosis)/length(pred3)
comb_accuracy <- sum(combPred==testing$diagnosis)/length(combPred)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
#######
#Problem2
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
adData = data.frame(diagnosis,predictors)
training = adData[ inTrain,]
set.seed(62433)
#Build three different models
mod1<- train(diagnosis~., method ='rf', data=training)
testing = adData[-inTrain,]
mod2 <- train(diagnosis~., method ="gbm", data=training)
pred1 <- predict(mod1, testing)
mod3 <- train(diagnosis~., method ="lda", data=training)
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
pred2 <- predict(mod2, testing)
combModFit <- train(diagnosis~., method="rf", data=predDF)
pred3 <- predict(mod3, testing)
combPred <- predict(combModFit, predDF)
mod1_accuracy <- sum(pred1==testing$diagnosis)/length(pred1)
mod2_accuracy <- sum(pred2==testing$diagnosis)/length(pred2)
mod3_accuracy <- sum(pred3==testing$diagnosis)/length(pred3)
comb_accuracy <- sum(combPred==testing$diagnosis)/length(combPred)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
pred2 <- predict(mod2$finalModel, testing)
pred2 <- predict(mod2$finalModel, testing)
pred1 <- predict(mod1, training)
pred2 <- predict(mod2, training)
pred3 <- predict(mod3, training)
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combModFit <- train(diagnosis~., method="rf", data=predDF)
combPred <- predict(combModFit, predDF)
mod1_accuracy <- sum(pred1==testing$diagnosis)/length(pred1)
mod2_accuracy <- sum(pred2==testing$diagnosis)/length(pred2)
mod3_accuracy <- sum(pred3==testing$diagnosis)/length(pred3)
comb_accuracy <- sum(combPred==testing$diagnosis)/length(combPred)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=training$diagnosis)
combModFit <- train(diagnosis~., method="rf", data=predDF)
combPred <- predict(combModFit, data.frame(pred_1, pred2, pred3, testing$diagnosis))
combPred <- predict(combModFit, data.frame(pred1, pred2, pred3, testing$diagnosis))
#prediction
pred1 <- predict(mod1, testing)
pred2 <- predict(mod2, testing)
pred3 <- predict(mod3, testing)
combPred <- predict(combModFit, data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis))
#prediction
pred1_t <- predict(mod1, testing)
pred2_t <- predict(mod2, testing)
pred3_t <- predict(mod3, testing)
combPred_t <- predict(combModFit, data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis))
mod1_accuracy <- sum(pred1_t==testing$diagnosis)/length(pred1_t)
mod2_accuracy <- sum(pred2_t==testing$diagnosis)/length(pred2_t)
mod3_accuracy <- sum(pred3_t==testing$diagnosis)/length(pred3_t)
comb_accuracy <- sum(combPred_t==testing$diagnosis)/length(combPred_t)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
pred1 <- predict(mod1, training)
#Build three different models
mod1<- train(diagnosis~., method ='rf', data=training)
mod2 <- train(diagnosis~., method ="gbm", data=training)
mod3 <- train(diagnosis~., method ="lda", data=training)
pred1 <- predict(mod1, training)
pred2 <- predict(mod2, training)
pred3 <- predict(mod3, training)
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=training$diagnosis)
combModFit <- train(diagnosis~., method="rf", data=predDF)
#prediction
pred1_t <- predict(mod1, testing)
pred2_t <- predict(mod2, testing)
pred3_t <- predict(mod3, testing)
combPred_t <- predict(combModFit, data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis))
mod1_accuracy <- sum(pred1_t==testing$diagnosis)/length(pred1_t)
mod2_accuracy <- sum(pred2_t==testing$diagnosis)/length(pred2_t)
mod3_accuracy <- sum(pred3_t==testing$diagnosis)/length(pred3_t)
comb_accuracy <- sum(combPred_t==testing$diagnosis)/length(combPred_t)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
rm(list = ls())
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model_rf = train(diagnosis ~ ., method = 'rf', data = training)
model_gbm = train(diagnosis ~ ., method = 'gbm', data = training)
model_lda = train(diagnosis ~ ., method = 'lda', data = training)
pred_rf = predict(model_rf, training)
pred_gbm = predict(model_gbm, training)
pred_lda = predict(model_lda, training)
comb_data = data.frame(rf = pred_rf, gbm = pred_gbm, lda = pred_lda, diagnosis = training$diagnosis)
model_comb = train(diagnosis ~ ., method = 'rf', data = comb_data)
pred_rf_test = predict(model_rf, testing)
pred_gbm_test = predict(model_gbm, testing)
pred_lda_test = predict(model_lda, testing)
comb_data_test = data.frame(rf = pred_rf_test, gbm = pred_gbm_test, lda = pred_lda_test, diagnosis = testing$diagnosis)
pred_comb_test = predict(model_comb, comb_data_test)
accuracy_rf = sum(pred_rf_test == testing$diagnosis) / length(pred_rf_test)
accuracy_gbm = sum(pred_gbm_test == testing$diagnosis) / length(pred_gbm_test)
accuracy_lda = sum(pred_lda_test == testing$diagnosis) / length(pred_lda_test)
accuracy_comb = sum(pred_comb_test == comb_data_test$diagnosis) / length(pred_comb_test)
# Accuracy Results:
#   RF  : 0.7683
#   GBM : 0.7927
#   LDA : 0.7683
#   COMB: 0.7927
c(accuracy_rf, accuracy_gbm, accuracy_lda, accuracy_comb)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
c(accuracy_rf, accuracy_gbm, accuracy_lda, accuracy_comb)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
#Build three different models
mod1<- train(diagnosis~., method ='rf', data=training)
mod2 <- train(diagnosis~., method ="gbm", data=training)
mod3 <- train(diagnosis~., method ="lda", data=training)
pred1 <- predict(mod1, training)
pred2 <- predict(mod2, training)
pred3 <- predict(mod3, training)
#Fit a model that combines predictors
predDF <- data.frame(pred1, pred2, pred3, diagnosis=training$diagnosis)
combModFit <- train(diagnosis~., method="rf", data=predDF)
#prediction
pred1_t <- predict(mod1, testing)
pred2_t <- predict(mod2, testing)
pred3_t <- predict(mod3, testing)
combPred_t <- predict(combModFit, data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis))
mod1_accuracy <- sum(pred1_t==testing$diagnosis)/length(pred1_t)
mod2_accuracy <- sum(pred2_t==testing$diagnosis)/length(pred2_t)
mod3_accuracy <- sum(pred3_t==testing$diagnosis)/length(pred3_t)
comb_accuracy <- sum(combPred_t==testing$diagnosis)/length(combPred_t)
c(mod1_accuracy, mod2_accuracy, mod3_accuracy, comb_accuracy)
comb_accuracy <- sum(combPred_t==testing$diagnosis)/length(combPred_t)
combPred_t <- predict(combModFit, data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis))
#prediction
pred1_t <- predict(mod1, testing)
pred2_t <- predict(mod2, testing)
pred3_t <- predict(mod3, testing)
combPred_t <- predict(combModFit, data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis))
combModFit <- train(diagnosis~., method="rf", data=predDF)
combPred_t <- predict(combModFit, data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis))
pred1 <- predict(mod1, training)
pred2 <- predict(mod2, training)
pred3 <- predict(mod3, training)
combPred_t <- predict(combModFit, data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis))
library(lubridate) # For year() function below
library(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
ttest <- ts(testing$visitsTumblr)
mod <- bats(tstrain)
pred <-forecast(mod, h=length(ttest), level=0.95)
accuracy(pred, testing$visitsTumblr)
accuracy_percentage <- sum(pred$lower<= testing$visitsTumblr&testing$visitsTumblr<=pred$upper)/length(testing$visitsTumbl)
accuracy_percentage
