---
title: "Unsupervised Prediction"
author: "Katherine Shim"
date: "December 6, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(caret)
library(ggplot2)
```

### Key ideas

* Sometimes you don't know the labels for prediction
* To build a predictor
    + Create clusters
    + Name clusters
    + Build predictor for clusters
* In a new data set
    + Predict clusters
    
### Example - Iris data
```{r}
data(iris)
inTrain <- createDataPartition(y=iris$Species,
                              p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
```

### K-mean clustering
```{r}
kMeans1 <- kmeans(subset(training,select=-c(Species)),centers=3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
```
    
### Compare to real labels - name the clusters
```{r}
table(training$cluster, training$Species)
```

### Build predictor
We can see that cluster 1 and 3 get mixed up and gets virginica. This is due to the error on building clusters and model.
```{r}
modFit <- train(clusters ~.,data=subset(training,select=-c(Species)),method="rpart")
table(predict(modFit,training),training$Species)
```

### Apply on test
```{r}
testClusterPred <- predict(modFit, testing)
table(testClusterPred, testing$Species)
```