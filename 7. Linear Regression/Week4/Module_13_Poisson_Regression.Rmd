---
title: "Poisson Regression"
author: "Katherine Shim"
date: "November 11, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Poisson distribution

*The Poisson distribution is a useful model for counts and rates
* Here a rate is count per some monitoring time
* Some examples uses of the Poisson distribution
    + Modeling web traffic hits
    + Incidence rates
    + Approximating binomial probabilities with small $p$ and large $n$
    + Analyzing contigency table data. A contingency table is a type of table in a matrix format that displays the (multivariate) frequency distribution of the variables. 

### The Poisson mass function

* $X \sim Poisson(t\lambda)$ if
\[
P(X = x) = \frac{(t\lambda)^x e^{-t\lambda}}{x!}
\]
For $x = 0, 1, \ldots$.
* $\lambda$ is rate of counts per unit time and $t$ is the total time. 

* The mean of the Poisson is $E[X] = t\lambda$, thus $E[X / t] = \lambda$
* The variance of the Poisson is $Var(X) = t\lambda$.
* The Poisson tends to a normal as $t\lambda$ gets large.
```{r}
par(mfrow = c(1, 3))
plot(0 : 10, dpois(0 : 10, lambda = 2), type = "h", frame = FALSE)
plot(0 : 20, dpois(0 : 20, lambda = 10), type = "h", frame = FALSE)
plot(0 : 200, dpois(0 : 200, lambda = 100), type = "h", frame = FALSE) 
```

### Simulation for showing that the mean and variance are equal
```{r}
x <- 0 : 10000; lambda = 3
mu <- sum(x * dpois(x, lambda = lambda))
sigmasq <- sum((x - mu)^2 * dpois(x, lambda = lambda))
c(mu, sigmasq)
```

### Poisson regression example: Website Traffict
* Since the unit of time is always one day, set $t = 1$ and then
the Poisson mean is interpretted as web hits per day. (If we set $t = 24$, it would
be web hits per hour).

### Linear regression

\[ NH_i = b_0 + b_1 JD_i + e_i \]

* $NH_i$ - number of hits to the website
* $JD_i$ - day of the year (Julian day)
* $b_0$ - number of hits on Julian day 0 (1970-01-01)
* $b_1$ - increase in number of hits per unit day
* $e_i$ - variation due to everything we didn't measure

### Poisson regression

* Taking the natural log of the outcome has a specific interpretation.
* Consider the model
\[ \log(NH_i) = b_0 + b_1 JD_i + e_i \]
* $NH_i$ - number of hits to the website
* $JD_i$ - day of the year (Julian day)
* $b_0$ - log number of hits on Julian day 0 (1970-01-01)
* $b_1$ - increase in log number of hits per unit day
* $e_i$ - variation due to everything we didn't measure


### Exponentiating coefficients

* $e^{E[\log(Y)]}$ geometric mean of $Y$. This is a population geometric mean.
    + This is estimated by $e^{\frac{1}{n}\sum_{i=1}^n \log(y_i)} = (\prod_{i=1}^n y_i)^{1/n}$. The geometric mean of sample $y_i$ is exponentiate of the arithmatic mean of the log $y_i$.
* When you take the natural log of outcomes and fit a regression model, your exponentiated coefficients
estimate things about geometric means.
* $e^{\beta_0}$ estimated geometric mean hits on day 0
* $e^{\beta_1}$ estimated relative increase or decrease in geometric mean hits per day
* There's a problem with logs with you have zero counts, adding a constant works

###Rates
\[ E[NHSS_i | JD_i, b_0, b_1]/NH_i = \exp\left(b_0 + b_1 JD_i\right) \]

\[ \log\left(E[NHSS_i | JD_i, b_0, b_1]\right) - \log(NH_i)  =  b_0 + b_1 JD_i \]

\[\log\left(E[NHSS_i | JD_i, b_0, b_1]\right) = \log(NH_i) + b_0 + b_1 JD_i \]
