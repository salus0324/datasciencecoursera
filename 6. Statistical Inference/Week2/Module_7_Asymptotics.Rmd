---
title: "Asymptotics"
output: html_document
header-includes:
    - \usepackage{setspace}\doublespacing
---

```{r setup, include=FALSE}
library(UsingR)
knitr::opts_chunk$set(echo = TRUE)
```

##Asymtotics

* Asymtotics is the term for the behavior of statistics as the sample size limits to infinity.  
* Asymtotics are incredibly useful for simple statistical inference and approximations.
* Asymtotics form the basis for frequency interpretation of probabilities (the long run proportion of times an event occurs)  
  
###The law of large numbers

* It says that the average limits to what its estimating, the population mean
* Example: $\overline{X}_n$ could be the average of the result of n coin flips. As we flip a fair coin over and over, it eventually converges to the true probability of a head.
* LLN says that the sample mean is iid samples is consisitent for the population mean. The sample variance and std of iid random variables are consistent as well.

###The central limit theorem (CLT)
CLT states that the distribution of averages of iid variables (properly normalized) becomes that of a standard normal as the sample size increases.

* $\overline{X}_n$ is approximately $N(\mu, \sigma^2/n)$

###Confidence intervals

* $\overline{X}$ is approximately normal with mean $\mu$ and $\sigma/\sqrt{n}$ according to CLT. 
* Therefore, probability $\overline{X}$ is bigger than $\mu +2\sigma/\sqrt{n}$ or smaller than $\mu -2\sigma/\sqrt{n}$  is 5%. 
* $\overline{X}_n\pm2\sigma/\sqrt{n}$ is called a 95% interval for $\mu$. This is saying that there is 95% of chance $\mu$ being included in this interval. 
* **Example1**: Give a CI for the average height of sons.
```{r}
data(father.son)
x <- father.son$sheight
#Divided by 12 for unit conversion from ft to in
(mean(x)+c(-1,1)*qnorm(0.975)*sd(x)/sqrt(length(x)))/12
```
So if we were willing to assume that the sons from this data were and ideal draw from a population of interest. Then the 95% confidence interval for the average height to the sons would be 5.71 to 5.74.  

###Binomial proportion confidence interval

* $X_i$ is binary variable with success probability $p$. Then $\sigma^2 =p(1-p)$. Then the interval takes the form \[\hat{p}\pm z_{1-\alpha/2} \sqrt{\frac{p(1-p)}{n}}\]  
* Replacing $p$ by $\hat{p}$ in the standard error results in what is called a Wald confidence interval for p. 
* For 95% intervals
\[\hat{p}\pm\frac{1}{\sqrt{n}}\]
is a quick CI estimate for p
* **Example2**: Your campaign advisor told you that in a random sample of 100 likely voters, 56 intent to vote for you. Can you relax? Do you have this race in the bag? Without access to a computer or calculator, how precise is this estimate?  
The rough estimation is $0.56\pm 1/\sqrt{100} = (0.46, 0.66)$. You can't relax!!  
```{r}
0.56+c(-1,1)*qnorm(0.975)*sqrt(0.56*0.44/100)
binom.test(56,100)$conf.int
```
Rough guidelines, 100 for 1 decimal place, 10,000 for 2, 1,000,000 for 3.
```{r}
round(1/sqrt(10^(1:6)),3)
```

###Agresti/Coull confidence interval
* **Simulation**: How well does wald CI work when true probability is not available
```{r}
n<-20
pvals <- seq(0.1,0.9, by=0.05)
nosim<-1000
coverage <- sapply(pvals, function(p) {
  phats <- rbinom(nosim, prob=p, size=n)/n
  ll <- phats - qnorm(0.975)*sqrt(phats*(1-phats)/n)
  ul <- phats + qnorm(0.975)*sqrt(phats*(1-phats)/n)
  mean(ll<p&ul>p)
})
plot(pvals, coverage, type="l")
abline(h=0.95, col="red")
```
  
* From the simulation, we can tell that wald CI works well when p is close to 0.5. This is because n isn't large enough for the CLT to be applicable for many of the values of p.  
```{r}
#First let's show that coverage gets better with larger n.
nL <- 1000
pvalsL <- seq(0.1,0.9, by=0.05)
nosimL <- 1000
coverageL <- sapply(pvalsL, function(pL) {
  phatsL <- rbinom(nosimL, prob=pL, size=nL)/nL
  llL <- phatsL - qnorm(0.975)*sqrt(phatsL*(1-phatsL)/nL)
  ulL <- phatsL + qnorm(0.975)*sqrt(phatsL*(1-phatsL)/nL)
  mean(llL<pL & ulL>pL)
})
plot(pvalsL,coverageL, type="l")
abline(h=0.95, col="red")
```

* Quick fix, form the interval with $\frac{X+2}{n+4}$. Add 2 successes and 2 failures.
```{r}
#Use Agresti/Coull confidence interval
nAC <- 20
pvalsAC <- seq(0.1,0.9, by=0.05)
nosimAC <- 1000
coverageAC <- sapply(pvalsAC, function(pAC) {
  phatsAC <- (rbinom(nosimAC, prob=pAC, size=nAC)+2)/(nAC+4)
  llAC <- phatsAC - qnorm(0.975)*sqrt(phatsAC*(1-phatsAC)/nAC)
  ulAC <- phatsAC + qnorm(0.975)*sqrt(phatsAC*(1-phatsAC)/nAC)
  mean(llAC < pAC & ulAC > pAC)
})
plot(pvalsAC,coverageAC, type="l")
abline(h=0.95, col="red")
```
  
We can see that the coverage of Agresti/Coull confidence interval is better than that of the Wald confidence interval. However this is not necessarily good because Agresti/Coull CI could be too wide.

###Poisson interval

* $X \sim Poisson(\lambda t)$
* Estimate $\hat{\lambda} = X/t$
* $Var(\hat{\lambda})=\lambda/t$
* $\hat{\lambda}/t$ is our variance estimate
* Example: A nuclear pump failed 5 times out of 94.32 days, give a 95% CI for the failure rate per day.  
```{r}
x <- 5
t <- 94.32
lambda_hat <- x/t
SE <- sqrt(lambda_hat/t)
round(lambda_hat+c(-1,1)*qnorm(0.975)*SE,3)
poisson.test(x, T=94.32)$conf
```
* Simulation: Simulating the poisson coverage rate
```{r}
lambdavals <- seq(0.005, 0.1, by=0.01)
nosim<-1000
t <- 100
coverage <- sapply(lambdavals, function(lambda) {
  lhats <- rpois(nosim, lambda=lambda*t)/t
  ll <- lhats - qnorm(0.975)*sqrt(lhats/t)
  ul <- lhats + qnorm(0.975)*sqrt(lhats/t)
  mean(ll < lambda & ul > lambda)
})
plot(lambdavals, coverage, type="l")
abline(h=0.95, col="red")
```
  
The coverage gets pretty bad for small values of lambda. For small lambda, confidence interval is not really trustworthy. If we increase t to 1000 from 100, the coverage will improve as lambda becomes bigger.  
